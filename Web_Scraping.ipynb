{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iURcojKClOl"
      },
      "source": [
        "# Le fonctionnement des sites web"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztm9URVTAAlD"
      },
      "source": [
        "Tips : \n",
        "\n",
        "Ctrl + u pour ouvrir le texte Html dans une autre page\n",
        "Ctrl + f pour accéder à une recherche"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMN-TRr_EtzW"
      },
      "source": [
        "# Le language HTML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkgXmsKsCZ1f"
      },
      "source": [
        "<html>...</html>\tEncadre tout le code HTML (balise principale)\n",
        "<head>...</head>\tEn tête de la page\n",
        "<body>...</body>\tCorps de la page\n",
        "<h1> <h2>...<h6>\tTitres\n",
        "<img src=\"lien\" />\tImage\n",
        "<a href=\"lien\"> </a>\tLien hypertexte\n",
        "<p>...</p>\tParagraphe\n",
        "<ul>...</ul>\tListe à puces (non numérotée)\n",
        "<ol>...</ol>\tListe à puces (numérotée)\n",
        "<li>...</li>\tEléments de liste à puces\n",
        "<table>...</table>\tTable\n",
        "<tbody>...</tbody>\tCorps d'une table (regroupe une ou plusieurs balises <tr>)\n",
        "<tr>...</tr>\tLigne d'une table\n",
        "<td>...</td>\tCellule d'une table\n",
        "<div>...</div>\tDivision du contenu (prend un sens lorsqu'elle est associée à un attribut)\n",
        "<script>...</script>\tCode JavaScript"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rjx1-q7PENwV"
      },
      "source": [
        "Le Doctype <!DOCTYPE html> : une page HTML démarre toujours en précisant le doctype de notre document."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMXaI-PfEZZN"
      },
      "source": [
        "L'élément HTML : composé d’une paire de balises ouvrante <html> et fermante </html>. L’élément html va représenter notre page, on insérera tout le contenu de notre page à l’intérieur de celui-ci.\n",
        "\n",
        "L'élément head : <head> est un élément d’en-tête. Il va contenir des éléments qui vont servir à fournir des informations sur la page au navigateur, comme le titre de la page.\n",
        "\n",
        "L'élément body : <body> contiendra les éléments définissant les contenus de la page à destination de l’utilisateur comme les différents textes présents dans la page, les images, etc.\n",
        "\n",
        "L’élément meta : Cette balise va communiquer aux navigateurs les métadonnées de la page. Par exemple <meta charset =\"utf-8\"> définit l'encodage des caractères qui sera utilisé pour cette page.\n",
        "L'élément title : <title> va nous permettre d’indiquer le titre de la page visible sur le haut des onglets de votre navigateur. Par exemple ici on aurait <title> DataScienTest - Train </title>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKI-vLaeEyiV"
      },
      "source": [
        "# Le language CSS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVtjGGKlFY5Y"
      },
      "source": [
        "Dans une feuille de style CSS, on trouve trois éléments différents :\n",
        "\n",
        "Des noms de balises : On écrit les noms des balises dont on veut modifier le style. Par exemple, si je veux modifier l'apparence de tous les paragraphes <p>, le bloc CSS définissant leur style doit être précédé de p.\n",
        "\n",
        "Des propriétés CSS : Les « effets de style » de la page sont rangés dans des propriétés. Dans l'exemple ci-dessous, nous modifions les propriétés suivantes :\n",
        "color, qui définit la couleur du texte.\n",
        "\n",
        "font-size, qui définit la taille de la police.\n",
        "\n",
        "text-align, qui définit l'alignement du texte.\n",
        "\n",
        "Des valeurs : Pour chaque propriété CSS, on doit indiquer une valeur. Par exemple, pour la propriété color, il faut indiquer le nom de la couleur. Pour font-size, il faut indiquer quelle taille on veut, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mByoRvoWFlmQ"
      },
      "source": [
        "p         # On modifie le style des paragraphes (balise <p>)\n",
        "{\n",
        "    color: red;         # La couleur du texte sera rouge\n",
        "    text-align: center; # Le texte sera centré\n",
        "    font-size: 20px;    # La taille de la police sera de 20 pixels\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwEKFzt1GQBs"
      },
      "source": [
        "# L'attribut Class et Id"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw5T_WqUF3mQ"
      },
      "source": [
        "!DOCTYPE html>\n",
        "<html>\n",
        "    <head>\n",
        "        <meta charset=\"utf-8\" />\n",
        "        <link rel=\"stylesheet\" href=\"style.css\" />\n",
        "        <title> Introduction au CSS</title>\n",
        "    </head>\n",
        "\n",
        "    <body>\n",
        "        <h1>Mon premier site</h1>\n",
        "\n",
        "        <p class=\"introduction\">Bienvenue sur mon premier site !</p>\n",
        "        <p> Merci à <em>DataScientest</em> de me faire comprendre comment fonctionnent les sites web!</p>\n",
        "    </body>\n",
        "</html>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQD6GHj8F3WU"
      },
      "source": [
        "La classe \"introduction\" permettra de définir un style particulier aux paragraphes de cette classe. Pour définir le style de cette classe dans le fichier CSS, il faudra indiquer le nom de votre classe en commençant par un point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMANJMgjGDHK"
      },
      "source": [
        ".introduction\n",
        "{\n",
        "    color: blue; # Seuls les paragraphe de la classe \"introduction\" seront bleus\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VsVBBEVGN84"
      },
      "source": [
        "L'attribut id permet de donner un identifiant unique à un élément de la page : il ne peut être utilisé qu'une fois dans le code.\n",
        "\n",
        "<img src=\"images/logo.png\" id=\"logo\" />\n",
        "Pour définir le style de cet élément en particulier dans le code CSS, il faut s'y réferer en précedant l'identifiant par le caractère # :\n",
        "\n",
        "#logo\n",
        "{\n",
        "     text-align: center;  # Le logo sera au centre de la page\n",
        "}\n",
        "Il faut retenir les attributs id et classe car ils nous permettront d'identifier les éléments qui nous intéresseront pour le Web Scraping."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0Qq-3FDHTnL"
      },
      "source": [
        "# Web Scraping avec le package BeautifulSoup "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azyYfN2HHqSN"
      },
      "source": [
        "La méthode de Web Scraping avec le package BeautifulSoup est une méthode dite statique car elle ignore le JavaScript (présenté dans la suite) et ne fait qu'exploiter le code source de la page web considérée.\n",
        "\n",
        "On l'oppose aux méthodes dynamiques qui, elles, permettent de scraper les sites dont le contenu est généré par du script JavaScript.\n",
        "\n",
        "Il est possible de faire du scraping dynamique avec le package Selenium de Python, qui ne sera pas présenté dans cet exercice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_IXW3aiLnYh"
      },
      "source": [
        "# Le Javascript"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKYxbFEQLsTQ"
      },
      "source": [
        "Le JavaScript est un langage de programmation de scripts employé dans les pages web interactives (animations, chats instantanés, google maps sont créés avec du JavaScript).\n",
        "\n",
        "Il constitue l'essentiel de ce que l'on apprécie en naviguant sur des pages webs modernes : animations, contenu réactif au comportement de navigation, contrôle du contenu multimédia, etc..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oyCpOg9L4_2"
      },
      "source": [
        "# Beautiful Soup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Glj32_ppHrq9"
      },
      "source": [
        "# On débute par importer les packages\n",
        "\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqX2X2q0MXmo"
      },
      "source": [
        "# la fonction urlopen récupére le code HTML de la page web qui nous intéresse (ici le top 111 de SensCritique), on stocke le tout dans une variable nommée page \n",
        "page_SC = urlopen(\"https://www.senscritique.com/films/tops/top111\")\n",
        "\n",
        "# On crée une instance soup de la classe BeautifulSoup pour décrypter ce code HTML\n",
        "soup = BeautifulSoup(page_SC, 'html.parser')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nV2ztR0cSIhD"
      },
      "source": [
        "Création d'un dataframe avec les données du site senscritique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA7TFM7zRAQL"
      },
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "page_SC = urlopen(\"https://www.senscritique.com/films/tops/top111\")\n",
        "\n",
        "soup = BeautifulSoup(page_SC, 'html.parser')\n",
        "\n",
        "#noms_SC est une liste contenant tous les titres de film mais également le code HTML (les balises \"a\" encadrant les titres), pour extraire uniquement le texte, on se sert de l'attribut text\n",
        "\n",
        "noms_SC = soup.findAll(name='a', attrs={'class': 'elco-anchor'})\n",
        "titre_SC = [] # On crée une liste vide qui contiendra tous les titres propres puis comme L'attribut ne peut être utilisé que pour un seul élément à la fois, on fait une boucle\n",
        "for element in noms_SC:\n",
        "    titre_SC.append(element.text)\n",
        "    \n",
        "print(titre_SC)\n",
        "\n",
        "annee_sortie_SC = []\n",
        "for element in soup.findAll('span', attrs={'class': 'elco-date'}):\n",
        "    annee_sortie_SC.append(element.text.strip(\"()\")) # On retire les parenthèses\n",
        "    \n",
        "note_SC = []\n",
        "for element in soup.findAll('a', attrs={'class': 'erra-global'}):\n",
        "    note_SC.append(element.text.strip()) # On retire les espaces inutiles\n",
        "    \n",
        "# Création du DataFrame\n",
        "\n",
        "sens_critique = pd.DataFrame(list(zip(titre_SC,annee_sortie_SC,note_SC)), columns=[\"Titre\",\"Annee_sortie_SC\",\"Note_SC\"])\n",
        "\n",
        "sens_critique.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_LeWrHKSRpX"
      },
      "source": [
        "Création d'un dataframe avec les données de Imdb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqxQk1mGRYHw"
      },
      "source": [
        "page_imdb = urlopen(\"https://www.imdb.com/chart/top\")\n",
        "\n",
        "soup = BeautifulSoup(page_imdb, 'html.parser')\n",
        "\n",
        "titre_imdb = []\n",
        "for element in soup.select(\".titleColumn a\"):\n",
        "    titre_imdb.append(element.text)\n",
        "    \n",
        "annee_sortie_imdb = []\n",
        "for element in soup.findAll(name='span', attrs={'class': 'secondaryInfo'}):\n",
        "    annee_sortie_imdb.append(element.text.strip(\"()\"))\n",
        "    \n",
        "note_imdb = []\n",
        "for element in soup.select('.ratingColumn strong'):\n",
        "    note_imdb.append(element.text)\n",
        "\n",
        "# Création du DataFrame\n",
        "\n",
        "imdb = pd.DataFrame(list(zip(titre_imdb,annee_sortie_imdb,note_imdb)), columns=[\"Titre\",\"Annee_sortie_imdb\",\"Note_imdb\"])\n",
        "\n",
        "imdb.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5v4prgjSaoc"
      },
      "source": [
        "Nous comparons les résultats en effectuant un merge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-u0h-5VR-uN"
      },
      "source": [
        "from scipy.stats import ttest_rel\n",
        "\n",
        "# Retirer les accents de la colonne \"Titre\"\n",
        "\n",
        "imdb[\"Titre\"] = imdb[\"Titre\"].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
        "sens_critique[\"Titre\"] = sens_critique[\"Titre\"].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
        "\n",
        "# Mettre tout en majuscule\n",
        "\n",
        "imdb[\"Titre\"] = imdb[\"Titre\"].str.upper()\n",
        "sens_critique[\"Titre\"] = sens_critique[\"Titre\"].str.upper()\n",
        "\n",
        "# Merge\n",
        "\n",
        "note_finale = imdb.merge(sens_critique, how=\"inner\", left_on=\"Titre\", right_on=\"Titre\", )\n",
        "\n",
        "note_finale[\"Note_imdb\"] = pd.to_numeric(note_finale[\"Note_imdb\"])\n",
        "note_finale[\"Note_SC\"] = pd.to_numeric(note_finale[\"Note_SC\"])\n",
        "\n",
        "# T-test\n",
        "\n",
        "ttest_rel(note_finale[\"Note_imdb\"],note_finale[\"Note_SC\"])\n",
        "\n",
        "# La p-value du test de Student est inférieure à 0,05, on rejette donc l'hypothèse que les \n",
        "# moyennes sont égales. Comme la statistique de test est positive, la différence entre la moyenne \n",
        "# IMDB et la moyenne Sens Critique est elle aussi positive, ce qui suggère que les utilisateurs \n",
        "# IMDB sont plus cléments que les utilisateurs Sens Critique quant à la notation."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7-ptlwK57qF"
      },
      "source": [
        "# Web Scraping sur Google"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-hrdsb_7M0a"
      },
      "source": [
        "# Installer la bibliothèque dans notre jupyter Notebook\n",
        "pip install google\n",
        "\n",
        "# Importer la bibliothèque dans notre jupyter Notebook\n",
        "\n",
        "from google search import search\n",
        "\n",
        "# Créer une liste vide et utiliser une boucle for pour itérer le code\n",
        "\n",
        "for url in search(requête,    # la requête que vous voulez exécuter \n",
        "                  tld='com',  # le domaine\n",
        "                  lang='en',  # le langage\n",
        "                  num=10,     # nombre de résultat par page\n",
        "                  start=0,    # premier résultat à récupérer\n",
        "                  stop=None,  # dernier resultat à récupérer\n",
        "                  pause=2.0,  # delai entre les demandes HTTP\n",
        "               ):\n",
        "    print(url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5N_mcwB8PQu"
      },
      "source": [
        "# Web Scraping avec le package NewsPaper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QZktmLu-ZVM"
      },
      "source": [
        "# On installe la bibliothèque newspapers\n",
        "pip install newspaper3k\n",
        "\n",
        "# on importe le package\n",
        "from newspaper import Article\n",
        "\n",
        "#On instancie puis on éxécute\n",
        "article = Article(url)\n",
        "article.download()\n",
        "article.parse()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTeeNm2W-57l"
      },
      "source": [
        "# Importer le module Newspaper sous le nom Article\n",
        "from newspaper import Article\n",
        "\n",
        "# Saisir l'url du premier article qui apparaît lors d'une recherche sur ''la parité en intelligence artificielles'', puis le télécharger afin d'accéder à son contenu\n",
        "url = 'https://datascientest.com/parite-en-intelligence-artificielle-un-enjeu-cle'\n",
        "article = Article(url)\n",
        "article.download()\n",
        "article.parse()\n",
        "print(article.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJonNsXe_CDw"
      },
      "source": [
        "L'une des caractéristiques les plus intéressantes de la bibliothèque newspaper est qu'elle intègre des algorithmes de NLP (traitement du langage naturel) et peut renvoyer des mots-clés, des résumés et d'autres informations intéressantes.\n",
        "Pour que cela fonctionne, vous devez avoir installé le Natural Language Toolkit (NLTK) avec pip install nltk et avoir installé le package punkt de nlt avec nltk.download('punkt').\n",
        "\n",
        "article.nlp() fait fonctionner le traitement du langage naturel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vuj5TUnc_Lk8"
      },
      "source": [
        "Il est ensuite possible de récupérer de nombreuses informations sur l'article :\n",
        "\n",
        "- article.authors, qui renseigne les noms de l'auteur.\n",
        "- article.publish_date, qui nous donne la date de publication.\n",
        "- article.summary qui renvoie le résumé de l'article.\n",
        "- article.keyword qui nous donne les mots-clefs de l'article."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEx250of_e3t"
      },
      "source": [
        "article.nlp() # on fait avant tout fonctionner le langage naturel\n",
        "\n",
        "#  Puis on récupére les auteurs, la date de publication, le résumé et les mots clefs de l'article de notre blog sur la parité en intelligence artificielle.\n",
        "article.authors\n",
        "article.publish_date\n",
        "article.summary\n",
        "article.keywords"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}